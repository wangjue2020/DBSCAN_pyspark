{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1e8c1f23",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ddd64ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_label(filename):\n",
    "    '''\n",
    "    Load data with label specified\n",
    "    '''\n",
    "    data = []\n",
    "    with open(filename) as file:\n",
    "        lines = file.readlines()\n",
    "        for line in lines:\n",
    "            line = line.strip().split()\n",
    "            data_line = [float(i) for i in line]\n",
    "            data.append(data_line)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb055242",
   "metadata": {},
   "outputs": [],
   "source": [
    "def addKey(x, max_x, max_y, buffer):\n",
    "    mid_x = max_x / 2\n",
    "    mid_y = max_y / 2\n",
    "    cur = x\n",
    "    l = []\n",
    "    if cur[0] <=mid_x + buffer and cur[1]<=mid_y + buffer:\n",
    "        l.append((0,x))\n",
    "    if cur[0] > mid_x - buffer and  cur[1] <=mid_y + buffer:\n",
    "        l.append((1,x))\n",
    "    if  cur[0] <=mid_x + buffer and cur[1]>mid_y-buffer:\n",
    "        l.append((2,x))\n",
    "    if cur[0] > mid_x - buffer and cur[1] >mid_y-buffer:\n",
    "        l.append((3,x))\n",
    "    return l\n",
    "\n",
    "def reduce(x,y):\n",
    "    if isinstance(x[0], np.float64) and isinstance(y[0], np.float64):\n",
    "        return np.concatenate((x,y), axis=0).reshape((2,2))\n",
    "    elif isinstance(x[0], np.ndarray) and isinstance(y[0], np.float64):\n",
    "        return np.concatenate((y.reshape((1,2)),x), axis=0)\n",
    "    elif isinstance(x[0], np.float64) and isinstance(y[0], np.ndarray):\n",
    "        return np.concatenate((x.reshape((1,2)),y), axis=0)\n",
    "    else:\n",
    "        return np.concatenate((x,y), axis=0)\n",
    "def topd(x):\n",
    "    return (x[0], pd.DataFrame(x[1], columns = ['feature1','feature2']))\n",
    "def dataProcessing(data):\n",
    "    rdd = sc.parallelize(train_data,10)\n",
    "    max_x = max(data[:,0])\n",
    "    max_y = max(data[:,1])\n",
    "    rdd = rdd.map(lambda x: addKey(x, max_x, max_y, 3)).reduce(lambda x, y: x+y)\n",
    "    rdd = sc.parallelize(rdd).reduceByKey(lambda x, y: reduce(x,y)).map(topd)\n",
    "\n",
    "    return rdd.partitionBy(4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b38d67c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def Local_DBSCAN(df, distance=3, neighbours_cnt=3):\n",
    "    # df1: give points id\n",
    "    df1 = df.copy()\n",
    "    df1 = df1.rename(columns={'feature1': 'feature1_1', 'feature2': 'feature2_1'})\n",
    "    df2 = df1.copy()  # just points\n",
    "    df1[\"id_1\"] = range(1, len(df) + 1)\n",
    "    # df_distance, svae the distance between two points\n",
    "    df_distance = pd.DataFrame(columns=[\"id_1\", \"id_2\", \"distance_ab\"])\n",
    "    b = df2.loc[:, [\"feature1_1\", \"feature2_1\"]].values\n",
    "    for i in range(len(df2)):\n",
    "        a = df2.loc[i, [\"feature1_1\", \"feature2_1\"]].values\n",
    "        dfpair = df1[['id_1']].copy()\n",
    "        dfpair[\"id_2\"] = i + 1\n",
    "        dfpair[\"distance_ab\"] = np.sqrt(np.sum((a - b) ** 2, axis=1))  # compute the distance\n",
    "        df_distance = pd.concat([df_distance, dfpair])\n",
    "    # dfnears: save every point with their neighbours set\n",
    "    dfnears = df_distance[df_distance['distance_ab'] < distance]\n",
    "    dfnears = dfnears.groupby(\"id_1\").agg({\"id_2\": [len, set]})\n",
    "    dfnears.columns = [\"neighbours_cnt\", \"neighbours\"]\n",
    "    dfnears = dfnears[dfnears['neighbours_cnt'] >= neighbours_cnt]\n",
    "    dfnears = dfnears.reset_index()\n",
    "    # dfcores:save the neighbors which are also core points\n",
    "    core_ids = set(dfnears[\"id_1\"].values)\n",
    "    dfcores = dfnears.copy()\n",
    "    dfcores[\"neighbours\"] = [x & core_ids for x in dfcores[\"neighbours\"]]\n",
    "    set_list = list(dfcores[\"neighbours\"])\n",
    "    # merge the neighboures set\n",
    "    result = []\n",
    "    while len(set_list) > 0:\n",
    "        cur_set = set_list.pop(0)\n",
    "        intersect_idxs = []\n",
    "        for i in list(range(len(set_list) - 1, -1, -1)):\n",
    "            if cur_set & set_list[i]:\n",
    "                intersect_idxs.append(i)\n",
    "        while intersect_idxs:\n",
    "            for idx in intersect_idxs:\n",
    "                cur_set = cur_set | set_list[idx]\n",
    "            for idx in intersect_idxs:\n",
    "                set_list.pop(idx)\n",
    "            intersect_idxs = []\n",
    "            for i in list(range(len(set_list) - 1, -1, -1)):\n",
    "                if cur_set & set_list[i]:\n",
    "                    intersect_idxs.append(i)\n",
    "        result = result + [cur_set]\n",
    "    # core_clusters, give every cluster id\n",
    "    core_clusters = {i: s for i, s in enumerate(result)}\n",
    "    # cluster_map, give every point id\n",
    "    core_map = {}\n",
    "    for k, v in core_clusters.items():\n",
    "        core_map.update({vi: k for vi in v})\n",
    "    cluster_map = {}\n",
    "    for i in range(len(dfnears)):\n",
    "        id_a = dfnears[\"id_1\"][i]\n",
    "        neighbours = dfnears[\"neighbours\"][i]\n",
    "        cluster_map.update({idx: core_map[id_a] for idx in neighbours})\n",
    "    # cluster_list give every point cluster_id\n",
    "    cluster_list = []\n",
    "    for id_1 in df1[\"id_1\"]:\n",
    "        cluster_list.append(cluster_map.get(id_1, -1))\n",
    "    # update df1, add the cluster_id\n",
    "    df1[\"cluster_id\"] = cluster_list\n",
    "\n",
    "    # draw picture\n",
    "    df1.plot.scatter('feature1_1', 'feature2_1', s=100,\n",
    "                     c=list(df1['cluster_id']), cmap='rainbow', colorbar=False,\n",
    "                     alpha=0.6, title='Hands DBSCAN Cluster Result ')\n",
    "    return df1\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "432f58c9",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def plotResult(data,x='feature1',y='feature2'):\n",
    "    clusters_num = set(data['cluster_id'])\n",
    "    colors = ['#ddff95','#f1ccb8','#cf8878','#f1f1b8','#b8f1cc','#f1707d','#E0EEEE','#66CDAA','#66CDAA']\n",
    "    count=0\n",
    "    for c in clusters_num:\n",
    "        data.loc[data.cluster_id==c, 'colors'] = colors[count]\n",
    "        count+=1\n",
    "    scatter = plt.scatter(list(data[x]), list(data[y]), c=list(data['colors']))\n",
    "#     plt.legend(*scatter.legend_elements(),\n",
    "#                     loc=\"lower left\", title=\"Classes\")\n",
    "    plt.show()\n",
    "    return data\n",
    "\n",
    "# plotResult(res_0, 'feature1_a', 'feature2_a')\n",
    "# plotResult(res_1,'feature1_a', 'feature2_a')\n",
    "# plotResult(res_2,'feature1_a', 'feature2_a')\n",
    "# plotResult(res_3,'feature1_a', 'feature2_a')\n",
    "# plotResult(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac5b7436",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def clustering(x):\n",
    "    l = []\n",
    "    global eps\n",
    "    global minpts\n",
    "    \n",
    "    for e in x:\n",
    "        df = e\n",
    "        l.append(df[1])\n",
    "    dfdata = l[0]\n",
    "    output = Local_DBSCAN(dfdata,eps.value, minpts.value)\n",
    "    \n",
    "    return [output]\n",
    "\n",
    "\n",
    "# res.count()\n",
    "def merging(res):\n",
    "    res_0 = res.take(4)[0]\n",
    "    res_1 = res.take(4)[1]\n",
    "    res_1['cluster_id'] += (max(res_0['cluster_id'])+1)\n",
    "    res_2 = res.take(4)[2]\n",
    "    res_2['cluster_id'] += (max(res_1['cluster_id'])+1)\n",
    "    res_3 = res.take(4)[3]\n",
    "    res_3['cluster_id'] += (max(res_2['cluster_id'])+1)\n",
    "    res = pd.concat([res_0,res_1,res_2,res_3])\n",
    "    res = res.rename(columns ={'id_a': 'id', 'feature1_a': 'feature1', 'feature2_a':'feature2'})\n",
    "    res['coord'] = res.apply(lambda x: (x.feature1,x.feature2), axis=1)\n",
    "    output = res.copy()\n",
    "    coords = set(output['coord'])\n",
    "    for coord in coords:\n",
    "        clusters = set(output.loc[output.coord==coord, 'cluster_id'])\n",
    "        min_cluster = min(clusters)\n",
    "        output.loc[output.cluster_id.isin(clusters),'cluster_id'] = min_cluster\n",
    "    output = output.drop(columns=['id'])\n",
    "    output = output.drop_duplicates()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a9feb40a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[(0,\n",
       "       feature1  feature2\n",
       "   0      18.85     11.10\n",
       "   1       8.30     18.75\n",
       "   2       8.05     18.15\n",
       "   3       7.80     17.55\n",
       "   4       7.70     16.95\n",
       "   ..       ...       ...\n",
       "   93     17.20     11.95\n",
       "   94     17.50     11.70\n",
       "   95     17.85     11.50\n",
       "   96     18.45     11.25\n",
       "   97     18.15     11.35\n",
       "   \n",
       "   [98 rows x 2 columns])],\n",
       " [(1,\n",
       "        feature1  feature2\n",
       "   0       13.40      4.75\n",
       "   1       14.15      4.40\n",
       "   2       14.85      4.10\n",
       "   3       15.70      3.70\n",
       "   4       16.55      3.50\n",
       "   ..        ...       ...\n",
       "   132     17.50     11.70\n",
       "   133     17.85     11.50\n",
       "   134     18.15     11.35\n",
       "   135     18.85     11.10\n",
       "   136     18.45     11.25\n",
       "   \n",
       "   [137 rows x 2 columns])],\n",
       " [(2,\n",
       "        feature1  feature2\n",
       "   0        8.05     18.15\n",
       "   1        7.80     17.55\n",
       "   2        7.70     16.95\n",
       "   3        7.55     16.35\n",
       "   4        7.35     15.75\n",
       "   ..        ...       ...\n",
       "   102     15.80     13.50\n",
       "   103     15.90     13.40\n",
       "   104     15.95     13.25\n",
       "   105     16.15     12.95\n",
       "   106     16.00     13.10\n",
       "   \n",
       "   [107 rows x 2 columns])],\n",
       " [(3,\n",
       "        feature1  feature2\n",
       "   0       23.20     17.80\n",
       "   1       23.20     18.05\n",
       "   2       23.20     18.25\n",
       "   3       23.15     18.65\n",
       "   4       23.10     19.00\n",
       "   ..        ...       ...\n",
       "   147     15.80     13.50\n",
       "   148     15.90     13.40\n",
       "   149     15.95     13.25\n",
       "   150     16.15     12.95\n",
       "   151     16.00     13.10\n",
       "   \n",
       "   [152 rows x 2 columns])]]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "before = time.time()\n",
    "origin_data = np.array(load_data_label('./spiral.txt'))\n",
    "train_data = origin_data[:,:2]\n",
    "\n",
    "preprocess_rdd = dataProcessing(train_data)\n",
    "preprocess_rdd.glom().collect()\n",
    "eps = 3\n",
    "minpts = 2\n",
    "eps = sc.broadcast(eps)\n",
    "minpts = sc.broadcast(minpts)\n",
    "res = preprocess_rdd.mapPartitions(clustering)\n",
    "output = merging(res)\n",
    "print(time.time()-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "028ef557",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "t =plotResult(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b172817",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(list(train_data[:,0]), list(train_data[:,1]) )\n",
    "#     plt.legend(*scatter.legend_elements(),\n",
    "#                     loc=\"lower left\", title=\"Classes\")\n",
    "max_x = max(train_data[:,0])\n",
    "max_y = max(train_data[:,1])\n",
    "x1 = [max_x / 2 for i in range(round(max_y)+2)]\n",
    "y1 = [i for i in range(-1, round(max_y)+1)]\n",
    "y2 = [max_y / 2 for i in range(round(max_x)+2)]\n",
    "x2 = [i for i in range(-1, round(max_x)+1)]\n",
    "\n",
    "x3 = [max_x / 2 + 3 for i in range(round(max_y)+2)]\n",
    "y3 = [i for i in range(-1, round(max_y)+1)]\n",
    "y4 = [max_y / 2 + 3 for i in range(round(max_x)+2)]\n",
    "x4 = [i for i in range(-1, round(max_x)+1)]\n",
    "\n",
    "x5 = [max_x / 2 - 3 for i in range(round(max_y)+2)]\n",
    "y5 = [i for i in range(-1, round(max_y)+1)]\n",
    "y6 = [max_y / 2 - 3 for i in range(round(max_x)+2)]\n",
    "x6 = [i for i in range(-1, round(max_x)+1)]\n",
    "plt.plot(x1, y1,color='red')\n",
    "plt.plot(x2, y2,color='red')\n",
    "plt.plot(x3, y3,color='black', linestyle=':')\n",
    "plt.plot(x4, y4,color='black', linestyle=':')\n",
    "plt.plot(x5, y5,color='black', linestyle=':')\n",
    "plt.plot(x6, y6,color='black', linestyle=':')\n",
    "plt.show()\n",
    "print(time.time()-before)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f83adf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"time.txt\", \"a\")\n",
    "f.write(f\"{stop-start}\")\n",
    "f.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
